{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TicTacToe\n",
    "\n",
    "Tic-tac-toe is a simple two-player game. Players place Xs and Os on a $3 \\times 3$ game board until one player succeeds in placing three of her pieces in a row. The first player to do so wins. If neither player succeeds in obtaining three in a row before the board is filled up, the game ends in a draw. Figure 8-6 illustrates a tic-tac-toe game board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Figure 8-6: _A tic-tac-toe game board._**<br><img width=\"300\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAU8AAAFPCAIAAABCr9ulAAAACXBIWXMAAAsSAAALEgHS3X78AAAgAElEQVR42u29b0wbabonWsFOzNplBwZmyovvCVqbNKanA625jXVpdP90QiY5XxKYnGnpKgjmbqRlkvAhIhpatBTmHHLVqGkF9QeSDNqb1YBA2p05GcLo6p7QEEY6uzSSyWkFd7oxHeyzRDJjp2EBu2zhxG7uhzepVKreKsp2vW+VzfuoPyQOje2n3t/7/J7/B3Z3d5PhyNNbw5tz8+YqZ82NAQNtoYgQIVJwYlyfml69NZxm4xRFmRgmHgjY6mqJXjKSNBv/fmo6zbImO3PIzpgYxmRniFqIMnWH9uDAIPiTyc44u68Sw56FRBd9T28N81+pG/89OaPZyfdT03xlGmjLu+Mj5Fiqg/bSxobNuXmKov5ddxfRaXa2iDudtrpaA20x0HQyEiFoz0ISK8HQ6BgAucXlAgeS8E3V0M4dyvWpGU6/RBTK5tx8cOAG8INKGxuO9vUSnWQt4bv3QqNjQJn2XzQ72luJTtSVIuYXza/QPv2kt49oRLkkw5HI3XvgdBLJXZnrX0wTZaJFOyGcWYvJzlS0n+f+7GgjtignZXIKNFc5y0+dJDpRH+1v3K+RiPfE3xKlKHcyOY/d7HKSezMXiS76gMdOUZStrtZI00QnSNBe2thgrnICNmWucoKgXWIlmFgJEgXtyT9fIj8QjAcCRCFZi9FCc8rcnJtPsSzRiepyYHd3FzhLj863i72md4ZvgouACFT8XR9FF33cX+3nmo9c6iBqyU4Wz/+KAzxFUY628yRQp75tN9AWA20pbXxf8G8G2kKgLi+HeOzdQFsMFpLRyMF1Z14r01xFPCOUfrut7pj9XDP/39Js/ElvH+Hzsgf0J9yfLS4XsUVqXZ1ml4sE6hCivfzUSUdbq0DFm3PzjzsuP+64DJx5IjISXfQRLal1da5PTfNdJCIqox1wUWd3l6PtvOCHEivBJ7194bv3iL7khYsqE8ldIuS8IUU7EEd7q7O7S/z601vDXFE9kVfupYv/V36QiUiOkggQF1JlMUJfBXye643j8ysjbSFhZz4b4v+1sEvBUtHYt51X3uDejgpH23m6xo3i7Qrm6sSst4zRDgBvdrmWrnYLTnD47j1rXW1pYwOB+n6TjQezW94FwYvb3gXPg/tEOXmhtyJZmgofbsH1gRARSGEnjSITfxa/uBNaQ/R2BdP3hllvWaJdCvBpNh4cuEGwTVGUxfWG324t3MbMndCa2ECpK4J8UGHUemDQm2polwL85tw8SZAAv51vggrYwdmYmcXAjPjHrPznJ4necKOdA7zgrv1XEp+nqGQ4wpXHG2hLAaM9cu/P0NeZlrNqvQW/jstkZwrDtmPQm8poB4B/Z/gmPxWfDEdCI/s9vRwaHedCGOLS44IRdsnPLvklTu0Ztd7lKS8HVBj3Jh69qY92II72Vvfgp9xfw3+6t88zzJtzX+4HGi9loOgad4mnXq134fuGhUHj8egNFdqpV6PXwJ/TbHw/8/mnb9YjFPDsNCnnU1x2mbXwC7cKph0Lg94yEmMW/4/9F82h0XHuPg6NjO3PbhB+KbG5yqn6SL9UNBaZmGT9yxRF0e5qpuWs0WbVhI5C00VGm7XsxHG1wh/rU9PcXwWZDqI3TdF+riX8p9fz2EKj4yY7sw87lpzdXZxFMlrUn7US6B+ITEy+5IQUtXrzduXli/gvVpk4k1ooMtmZI5c6BFO6id50gXYDbTna1+vv+khAwzAAPhWNsX4/RVHxpeVULEZR1GHPexRFaeIF8Qu5UQyu2XgwK/jugf4B1r9c3X9dH3RUNfyk2Thfmak4S/SmF7RDTVlwYHBzbh7F/omd0NrGzOzWwsNt70IqGpP6MbrGzTSfKWs6XuyowKM7s8v5xnldCarrbUK/bGRiMhlae3voczz2QYqOqqtnA23hKzOxEkyz8awP0v7RW6ZSlOVBr3I62s4LDvfm3Ly6M6ojE5NftXzoPXE60D+wMTMrA3Wg30D/gPfE6eWea/I/qZYcerNOFlvZ7JZ3IdA/oC0dtTcjTCCBYUpEb3pBO0VRjvbWd4ZvCnpjo4s+VdrgN2ZmAW6l0pXyd4S36TTmWgB+qkItkWGekYnJ5Z5rWtHRYkdFWZPKcaY0b+xkjpUL+0pvmNDO2TeBTQuNjuWShE9FY990Xvmm80oubQPAVfum8wpSI2+00BzCrXXHVP/9TMtZ+YOL+kaToqMoPM/Sxvc5ZfJZPdGbjtBuq6utG/89P3+YZuNPftuXXZPclnfB23RardLijZlZX/uFLNiBQtmc+5L7mohoPNNyVqbEMtA/gLTjAkpHjTYriqpPbicUpUY/zP7RG1a0c6yeH5BPrARXM8+mhEbGfG0X1LXG7JIfHeCTkWdSPry6fF7mlHybGwnKgo6WnTiOItDFNw+qpDP3id4yY6Nq/SJnd5et7tj61Ayof1yfmja7nIIhtjKy3HONy5FKSYmn3uSo4Ic0Wf9yXII18Vm9r/1C7cgd1UeFPMdVNQx4KVQ/qWjsu55rtaN3MNJR5HVgaqU29pve8KGdoqjyUyfXp2a4vz69NWykLUqS8PJQL/HUMy1nZK5GdskfGh2X+Q2paOy7j3trR+6oe7ny08I5ln/tKa6e7rh/GUpStrwLq0O3KzsvYqCjJZ56RPOVEDVQF7zeNGDynAiWwAcHBvkVkVBZHbotBdRiR0Xt6J3a0Tvy5Ud0jbu6/7rnwX2ZGht2yb/8scrBWH6HJupN2EabVYaerA7dVt1bgdJRRJ1b6EYhFbbeNEa7yc4IRl/IAz4yMbk6dFsqFiAPYOjV4OrplnkMKgZjBXkHDL2A4OBK1WZ893GvukdWTEeLHRWI4kxIV+gVsN40RjtwupzdV/mvSAEe1MNIeVwyuJURR3tr7agkYw/0D6h1lycjEZm/oju4UtVg7JJf6t7MQtYf/AVmoFAdWdQRkELVm/ZopyiqtLFBMIUaCvjvPu6FRuDlo6l7SomnXsZFD/Z/pnPyKS90jVvq26nISwWl5q/iTKjSxRiIUkHqTRdopyjKfq5ZEJ8TAF5Kxa6e7tzvQvBoof+05V3YM/ivRFA76vLfTor4qMJLIxOT4lsYaeeWcAkHGqJUeHrTC9opiqq81CFIpQQHBoHnvBNagy5RKms6rlZnIgjdScVmcs/q2+pq+d/uOd4ZPlLlYqrwUgk6ijDOVNrYgKfLoMD0piO0G2jL0X/oFdjA0Oh4cGAQijejzVr9yXV1Hy2UJkjdNRl7g7wiEPwTu6S+XWh0LMeiY3FUGcNkJf45QXp1Fpje9IJ2ChaipyhqfWp685//24GiIjGHV53zuHq6ocHYwljPWN1/XXyYQN1ILnQU5nkirwzhpzNRX52FpDcdoZ16FaIXzGwrKi4+VF7OB3yJpx5F6NJos74FY25gmJGah1WjFYVvD30uTiZveReyzjWK70E9FHgTveUH2oFX5h78VNAbe+DgwUPl5UUHD4K/Hun8NaJ3l7pHVMy7UNqF6I0261uf9Ik50erNbGITW94FMZvFc2T5fju/AYHoLc/QDqT81EkpwBc7KpC6N5WdF8XPNfeVPYziLgCkQte43x76XExesqgdhG4sw5NA4pNePCHPwtCbTtEOAG+0vtneVFR0qLz8f7rwfyF932JHBVT10IekXPgTLHIcpZY7fxHnljZmZjPqHYZ6N9gmK2myQq8A9KZftG/MzLL+5XQiIQD8X//LH/csp8/ZdLSKzTs0Qapc+P3t/CCTJuJobxXPRVn+OIOhXdrGmTbn5oneCgrtWwsPKYp6sbn5YmNj98ULvtOrpH8mRz8N6kdBi58UilaROSmp/uS6IPKUES8Vx5lQe1h8iWm3RDSv9aZr2/4S3js7yWfPnq+v8/8VNeChZB5aEaEU7Sv6Qjs08qSQl0LbOXB6nlqFOfNdbzpF+05oTaCXH5JJAatHCnjoDMA9R9nKiIbFs1JC17grL1/Mgpdyy3/2ZEMFKftEb/jQvg0LgJv+rV2AmdVbw+hsJnS+b9Zknj8sUT97y8SO6J68dMu7IE5PYJ6spPnVmad60ynat7wPxS+WHf8/jvb1Chjd0tVuRICHRkqhHyxjNohgM1QujqiYl8rUjTwd+p34RdWHuuyFdlpz5Oej3nSK9rh/WfziYc97trpaQR4+l6m1SgCvlm3XLasH7dyCF1dv3pYa2CQ2UCWeeswJJBPzEyhpInrLS7RDVUa73RRFlZ86ebTvjf6ZZDiydLUbRb00IyLzqWgsu/Zmfp8mnmkWyqXEUy/oJgTD+cSOKNRA4e/c4tv22OLXRG95jHZo1Vqxo4IjTqWNDYL+mcRK8HHHZdXTsHSNW3z7bmdF5sWry3T1aCsvXxR8U/GwIKiB0mSyEj/wEdUuG5d3etMj2tOw2GaxwyF43gLAp9n4k96+J70qs/rDolwoKATImHy+uSdH2zMK5aXijiDBaiQJA6XBkRWs1tJQmfmlNz2inYU57ZaaavEFX3NjQLxM8nHHZRUff/mJD4QxhWwHFfFLpmI6Qzsl0RHEHdyNmVmxgTLarFqli+2/eN13EHvkI3pT/yLT8r2tViijq7kxEBy4wefwyXDE3/WRo+28KpNtxLZ9J7SWisYyTZyk2XiU52FG9Yd2iqJcPd0bD4Q1BaDYE5oTRTFlQIkkVoL82kQNXff80psebTvUMabd1RIBG8vRvt6jfb2ifZLjjzsu5x66M9qs4t5m1p+xeX/S28evBdKh6w6+rLhuBBxcaJOmVnT0yW/7+Pe75ldnvuhNj2iHo1r2LixtbKgb/72zu4uPebVCdxbRRRNfWs7oN0QXfeITqU/z7mhvVZIWKnZUZDfVO3dZn5oWX+J6aDTSud7yCe2KfOxTJwXnAITunma+VVKeVuysZTaTzMQwMDoa0KcalZR8vNV/XSsuCt2ZqYerU+d6yye0C2LyGUn47r1cWL04QJipbTfZGXG1rObeppQwLWflzZS28xJtdbXimbN6aDHUud7yC+2Kqo6k9kYCVp+dBYAMIYzFsjijwisjENDtk5Y3U2WiPAVmEXOl5+EI0dv+YvKU7GCANBv3d32UXducgH1lUU5nsFjEn0eHgTrOTOmZcFrrjukzCKJzvRUa2k125mhfr0yTWXBgMDgwmLnrnuuGXeu7kOFKejbvZSeO6/kpi19M6sO861lvhYZ2iqJKGxveGb4pY+TXp6ZzL7nL1LxDd7br1ranojGZ/h9o+RNOMcOUqYfuA53rTY9oF0fFgB4zo/TtrYLmGb5szs0vXe1WDjaTKGqQqetuoC2Q2JJew/Kh0TEZhW97F3LflpUT2quc4ierB9dd53rTI9qhZXNZFLSA5hmpnWGJlaBywKvSmagTqqnEQMmvx9nzB1BLdNEnfnCaq1f/eitAJi8wAu8M3yxtbMgd8LkfUAiTj+uRycsbKCAqLjYuGCkwvWFC+2HPexBg5DAQDpTWQlk9NsBDOzf0NpoyI/sDbeTGI+tTM0RvhWzbc4xwlDY2/Fg6Fb8n4LdzHlAlVQiQjwbq5RNZ8vvaL2hycPkNcERv+Y12aL1RLgt0gRy51FEuC3ikXwpaTqe3QbQ7oTXoxrsST724NUjDg2uucuJZ4V5getOpbRdHxeJqZC+kHHgAeJk8vLhFOYsMfOn7wnfXaqaajFcpfpFpOVs7eqd25I7MwcXvi2qyHKoA9KZHtFvETaZL/tzvQpCKt0kclPWp6fDde9AHI34xi5IpaIGNrgyUeG8RXeOu7r9OSe855Q5uRuvQchebqJyOP6yO6C2f0A7tZt/ObcsqRwLBxmgoi34KG1AfufdnVb6UuLpbV3T0ux7IOHRnz2/4JxjaxU1RVCoa+6bzirpb7uVF3Amn1ZT+/NKbHtEO7R/IZTGTQMpPnZQy8uJ51WrdvmJsH9IN2qGTEsU9W9C1h5ws91zDdnDFtYnQtmKit3yw7TVuMfkRDwPKEXvuwU/FBbbJcCQ4cOO1YYeNH4F6YlnRUb1w+2D/Z+IXodXH4q0JgoOLh5oKqBm0VJHoLT/QTsG6C+SLkLMTR3urmNVvzs2DiTepaEwwLfhlAKY5y0ngfLapH6hHJibFsQmjzQpt8IBuTXjj4H58LfcESl7cmwWgN72gvRxG5qHBz9xZvWBYNXDg02wcusovl019/J1QJdIJApySisagWpVZUVbiqZdp5Jb6hUilFLsyC0NvurHtsDVsUonNHEU8nT4Zjiy2/gpKrhxtrVn3MPPrZ0v1gfbVm7ehJqUEVtHISWXnRZkxLKpTMAVof5/oLY/RTklMAkFUaSwGfGo7esBgEBt2VSaB66Q+JDIxKbWocM8+bZkRa5jrRkobGzDXKRWG3vSFdqlBX772Cyg8HCHgi4qMNpvwArp8UZXhJHqo/WSX/Ms916Q4555fs9hRUf3Jda0+PJ8lMeeaid7yHu1S5j0VjX3V8ksUFv75/9jYTT6nfvgB/NVgNhcdPMh/lrlspOAfUM3L5lPRmK/9gqQbpWyCWlnTcWgIQybbpLqY7AzOEF3B6E2PaGdazkL9HKB0FZMWW94FX9sFX9uFxH//7y82N7nXD5aWHigqAleyfEx1T+HS+FrVgQi0J8MbD8s6n3xx9XSL+ZfM4CC1hOspxJlmLwC96RrtFEW9PfQ5lB2BOiRf24WtHGrsQNnjVy0f8n9PemeHA/yBgwcPlZcfPHxY6mMoF/1Mqln++JoMMyp2VCgvKBAnlqr7r2OYo5yMPCN6Qyra7IEz2qy1I3ek7tQt78JW2wJd42aazxz2vKdE3VvehWRojfUvb3sfSj28dCJRZDIZzGYAeGtN9b/5m7/J1Ry9GiCvbVv7TmhNnhNlyifpGvfPJv4A2pYOe+pVmfOjQJm+V7CPEL0VDtqBXt4e+vzbzitSJIpd8nO4BRekpaaam3jF+pfBMAzWn0FrzYvNzaKDBw8cPAjw+eh8u3ilbNZ+ezIc0SomvxMK7eE9ZV47RNe41aovVOgTcXOpsA2oKgC95QfaAYZlLLzAdFOwHtUsOMW//T8//P7+F8DfTrPxxx2Xs14dK5hUFVv0mex6nG8h1ZKtK9mc+1KgW80LE/NCb3ngt/MvQs/MfQy+jdFmrey86Jm5f+Tif3B2X+X/U2h03N/1URb2ZOvN5ZNR7dZCQYd8cnKk89f6P4gC7eHZ314AessntL/04Ufv/HToc0RODljB6Zm5X9n5Mq9e2tggyJZFF32POy5nunNGsGo2pt1uExkTJJUB0bltx7NRrwD0ljdMXhAOKWs6HpmYjEz8eUuNpvcST33ZiQ+kgnyVlzpiiz6+PU+z8eDAYHTx68pLHUqquNJsPMWy/FeS4YiGrjtd4xaHJ0s89WAAg85FTKywrYXKa71lKgd2d3f19plAYxzrX44vLe+EQvI1dtwFDGJ4tLvapCxrEl30+bs+Er9urnI6f3NVSeguGY7868Ag/1we7evVqlR+Y2aW3/ADyoGVLCTWiSRWgsHPbvBTG+7BTzG47vmut7xHOzZ5emsYOsfKQFuUx+rDd++FRsdA2C/rgJ9aAmiR0WrN0/BSaGQsNDoO/uzs7sJWnpjvessbv11DcbS1Qkl7mo0vXe1WmEK3n2vWT1t7iac+ryPJjvZWTpk4F8Xku97yzG/XRMAWCn74Nx2PA2sPAP/u+MiePnyajetk93ABSDIcIcokaEcltrpagWU2WCyATKbZ+JPePvfgp3sx+QmuWl5XIyjzksm/ovGU7uf5EiZfCGI/18LZ8+iiT97UpNn4+hevVxrpaiJ6Php2LotpoC3QhdlECNpVpvf8TvV/HRiU3zDFuZe2ulpi23MRfvGsra5Wb1t3CNoL1rxzAflkOCKzYep7XkHOIQL13GT9i9fK1NvKHYL2Qjbv/JVPMhum0rwCGxPzE6K6XESH63EJ2veFONpb+cne9alpMeDxbInfPzSeX+Cg1U4ogvb9Cvi283zXUQz4eCDAD9ERyUXigQC/7yD9ZlUyEYJ2tGKyM4KaeTHgcVaAFLwQZRK0aylgtxyfYa5PTT/p7YNy+HScEHsiBO2FJZtz80tXu8WAJ0EmNe28FjPqCNoJn2ecv7kqyP2CKVcCeKfixNVUTZ4TVk/QromId85QFJVm409vDRPbjsy2E7S/FnFBJ+jOAP+BwQri/8vf9ZFg+42RqFIh4I/29UL74QWA13ywfD4e4tgjn4C6J8OR8N17+tyfq66k2Xg8IDmn3MQwT37bl1gJgq9ffqopuvj15tyXfEeytLHBQNOljQ2Ru/eiiz5H23mwQs9ad0zQf31gd3c3NDKWCASP9vWS87cnmKEeOycaTrPIA3MdjsQWfYlAMLESjAcCWVcrmKucYK+uucppsLwkXFwLjdFCo75wk+HI5tw89y5S77g+Nc2Z3HQ8zqd+yUhEeQLCZGcMtAX87+YqZ+n7DeYql7isOLESTLNsOh43WCybX87b6mrFDd0Hdnd3vSf+tvzUSWd3FzmROQJe82kW2JQAghSJleDzSCSxEhRQTZOd4fa9pOKs0UJndL61CtCAz3zIzpiYn5jszKFXC6oSK0HOa5P6IuYqp4lhQMFvMvJMMActo4uM/wEsLpeBtqTZeGh0jPlFs5JGjDQbl2oxOBB/EnjccdlWVyto7eTuEsC4nr/yDcxVLj10LEQXfdxRS8VZqM8Mnp+17pi6n1kG8ODqBRMUuU/FP/oCAc/VQL80DpqQVeABxhZ9iZWg/jGpyS2guk7KT500u5wcIwCQxvBdDnx//4vgwKDJzrwzfDMZjnCfYPH8r8wu55FLHYLRa5yrUNrYUNr4PjbYAx4YXfw6EQhkFw8Dn1lq+FF00Rd75Istfs2deJOdsdbVlp9qEj8MaCGtijECwFTBXUBRVCIQTLPxQ3bG7HJyRWbgRe7/krry8lrKT50sbWwAj14w4VfnAi5ua92xZORZmmXBh7fV1YJXHG3nNWmXPPDXf5zgx5YdbecNNJ1mWf5cAXkIWetqwR3xPByJLn5tdjltr17JJURhtNAG2gIQnh0vkrqqSxsbShobwLsnVgKxxa/JvBSZe8dad0zwOjf+WV5vXI+6gbaAbRCA6CYCwWQksufdZLIzdeO/FxyV2COfgaaNtMXscpmrnNDJguB9rXXHpJ4s4MZifGZBbcB7GWiL2eXkc299PtADO38Ng6Af9+kplfo9uOvt9QPjxSoIwPSAZPGLhximtLEhzcZBcEgtZ4E7WmL0JiPPnocjBtqSCAQFYPM8+CcljhU3i95kZ8AtAP66OTcv9uASK8H1L6aT4Qi4eqzv1poYBljazbl5A23h+1PATzQxjDgjyP1feSQHdnd302w8fHdCoTEveAHD6hIrQW6SLLb4EIhUiy0PQKaBtuzJZvkjX8Rxb5OdYX7RrJx5YRZ/10cCGyAoWyaSoxjBEXG0tyYCQZBX2JNi2c81W+tqN+fmM12ukqMtysgvBeeen6Th8wsZzubsvgqG1dnPNa9PTScCwe+npjnrlCn+uUgh+DOYeCFlFrh4AXfo+dmdxErQ7HIaaHr9i2nw+iGGUR7e08NmNXk5ZGeoxTdeIeWJ6tt2jlmF70442ltDI2PJyLPSxgbOJ5EnUetfzIAdKSmWNdkZgAcTwyjn6uWnTnKRDDHIzS5X+akmW13t447LAsBzHhqINYT/dM9I0+U/byptfF+JTeAic9xHLW1sgNYdRBd9Rgu9/sW04APs6ekBpmAj8+oUCH+YPBA8CyT2I9qzls25+WQ4Yj/XLLAeXAQu9sgHLCqIG4PAuIG2gNHOfGQC1HG1E2L3LzQ69v3U9I9PnSxpbBDfRLmUsm3OzccWfVIT5mXuiz0L7DLaRUHQTtCua7TvZ1GCdgL4rJVJ0K6ukK6YnEQ8BRl4QGJWIl9yS4QIQbveRQzs8lMnoWY8o21T5OokQtCeB4A30BbQISsGPCi5JYBXfnUSIWjXtUUCYxiAoy6u0iUWnghBe+EIl5Az0BboTmICeBkhMTmC9jzmn87uriOXOgjgiRC0F4LsucPIfq5ZPDsgzcaDn90gUXoiBO15LNA9xGBStbgWiKTlhNoT9dsRIWjPQwoAG2WZWAkGB24Q5RAhaM8Xv53OCPCCzNzm3Dy6wRj5LiQDT9CuO6Ot/IBCAb8+NY2zmzCvblKSgVdTCn/CNLvkT8Vir7+w1UrXuDU8oCAVL4jJBwcGuZmHRIDk3awIgnbtxdd+IRWN8V+ha9w/m/iDhgcUCvgnvX2kc+YNZTIE7YTJZyIbM7MCqANrv+Vd0PaAirvi0mz8yW/7SIie0HiC9iwlfO/PqN+Cj89DmZBPMeCT4cjS1e79fBz5G2P2LGQgQtD+WlLR2MbMLOp34Y/cAQOhcwF8YiW4n0P0ZNkjQXu2NP6BJNSLHQ613sWWW0GIGPDrU9OCZX37R0p4e7WgdUpEcpFCjtJFJuA0vqzpeLGjQq13ib4arp71ATXQlvKfnwyFX4+4DY2Om+yM1KKL7GgO6/dTFBVfWgYZisOe9yiKKvHU6+qRbeXVioid0NpOKERR1Lb3IUVRRqvVUlONOulD0A5/ElKhOEfbeb2RT/u55h+fOhkcuMH5BYDP5wL4ndDaxszs1sLDbe+COFTJCV3jZprPqHsDqnM0LbQOzxW75N948Jdt70P5QG9Z0/HyEx+UnThutFkJ2tHTeAmPvdhRoTeDxll4R1srPwqwemuYvwshE1IzGRodZ5f8Co8vu+QP9A8wLWddPd36OZ26SkamorHQ6FhkYnIntKbw+G3MzBptA4621srOi4Xst6eiMYVHDSGNl4jGO9pU3sF6SL0iEHOVk98tl0Vj7MbMrPfE6eWea1noPzIx6W06vW9DBjKyOnTb23R6dei2QqjzgbA6dNt74jSijK/GaN8JrXlPnP7S0/hVy4f/7K5d7rmWqYLU+hjQ4260WZmWs+q+V6ZxeHkRrNZWDvhUNPZN55VvOq/kovBUNBboH/im84oM898/9hwQn69aPvW+4/sAACAASURBVFwdup2LQnZCa762C6tDtwsN7aHRMf5pi0xMftXyy8jEpE5oPAo/SvXQMRTw8juhtrwL3qbTaqUbN2Zmfe0XNGFnh/RUPxcaGfuq5UO19LA6dFvDaxQJ2uNLy2JzsdxzDTM/lKLxKDwoFMEkQT98mo0/6e2T6pwJjYz52i6oe4zYJb8mgBeUHmjopS/3XAv0D6huhMR13DgFU5Qu0D+QisXwhCukaHyJpx5F2Jl/QJ+HI1Sdar/23fGRJ7193Naq4MCgOGi33HNtT+pU4qk3OSr43531L8eX/PKcPxWN+dov1I7c0SqfpNUSOPDF5W86o81Ku90g38a9uO19yPr98mAG12jtyB1NoqEqo91SUy0VkFgdul3sqFDdbVZO45mWM6q/V5qNPzrfzrfJKv5yA21xD34aHBjkrHrwsxv8kRjyUC/x1DMtZ2ScF3bJHxodl/kNqWjsu497sR3NZDjC7YoBizd1CHWm5Wz5iQ/Kmo7LHL/Q6LhMWA5kQKr7r+P/dupvhpI/gj8d+lxGU6oI1NcqdlR4HtxH8Xb8XZRK9o1nIXzAczNwVoduSwV+ih0Vb/VfV5ho3AmtfddzTeZ0ljUd/+nQ53iOo/fE33J/RqRMefG1XZBSRYmn/q3+6wrp4ZZ34TvZELWrp9vR3or526mfgauWPWfLH19D6g1K0XhEnCIZjmBwL9Msy/dmH3dcfjr8/0hB3dHe6nlwX3lNQbGjonb0jqunW85YYQm7KF8KjEiWJW49o81a3X+9dvSOck+wxFP/s4k/ypy6QP8A/rAIknz720OfSzl7gByiC1RI0XjV0+wv0R6JCMCP4l2O9vXyfYRkOBL+z38sOngQetXK4FZGHO2ttaOSjB3P0dR25HZkYhLKSY02a+3InSysBbgjZB7Ht9hD9EjQDhQkBXh2yb/88TVUzwwWjWdaziLyPAW+pQD8Koqzu+uN9yoqOlReLgB8df/1XChMiadexkUP9n+G+iyW8lpiMMtOaA0agZc/yQqvUSkXfSe0Fhody3u0c2qSOjobM7MokvDSNP4MOg1iG7pQ0f5meT8AvMnE+YG5eyt0jbt25I6UI4q6bkIw+SeJsfv1u55rUDOrSkoClCRD/ymL+jw9on1PwAf6B1T/nlAaT9e4kRbGY5uLaqur/Zv/cOGHnR0B4A1mc1nTcbVCPnSNW8oW5VhSling0REl8bGBuuuunm61so+O9lapu1j1rL42aOdsBRTwqWjsux6V+TyUF6nb8aahbacoKvpo8cXm5u6LF/wXD5aWlv3v/5uK78K0nIUeTQzMU5NZdFC8lXjq1Y2ZS90dUndN/qH9pa345LoUOVQx2MvCykVQFMYLhD9QCenolZ3QWmRicveHH5LPnqUTCf4/Pf3df1R3RrWrpxsaf0aNdvyz6KTa2t5SOx9utFnf+qRPwkqNFwjaKYoqazouSQ5vqua3QONziELxUoLU1eSn3F5sbqa2t/n/ys/Jq3M0YY8sFY0h9d7xz6KDJjIrOy+iKLuka9zQctKNmVk83jumSVVMy1no91SRz0Oddgyle8p3xeRu2N9QHcu+2NwUAD58955a71jiqYdqTw+9XEgNu9FmRWckpO4RPFrFN5eusvMi9PSowuehtyOeeSx4mjShFvVgaYlgmeTTW8MqDrGs7LwojrnIDAVSVzBMpITOMkM9cAYan994MIsh9451CqVUmd3qzVyDvesP/gKj8eepQhEo2is7L4qXSa5PTasF+GJHBdTKSQ38yyO3SObaQt27VdZ0XIyCVDQmMzQ1L9FOSZTZpaKxXOptoJrS7UQqtZiL0WYtO3Gcgm2PVRHwjrZWsaGLTExq26etikAjjogaJQVypPPXsM8zXmhoB5FJ8QECc7yyBAOMBelnGFjusrXwUJ5wAsDzk9VqAV4qqYHBEKEWMChWIEgLsfh3itjmsXv1IOcf2imKomvcb8N6qpY/vpadxRBfipzdKxjbLn6x/MQHgvDBO8M3BXPpVQE8lMxDXac8EqmyS2zHBupmol52os32iBJPvTgnl4rGVm9mHJkEI1MxB1own0volS9uHDbQlqP/0Ks6pS92VIjfC7pgL68M+wL0WGI7NtDejQjiRWaa7YqBFmyFRsYyjfdCvR2cNJ4fOk7H49jOJfSHTXYGhQ9vbz5TYGR+C0bjwUYNnBDATOa13AxV3X9d7L1I9SdABRqfwxNo4YQfOkbRs5npuUQRtIPmMqEfLK9tO2a0Q12kbZTZTY33wL099LmAz+yE1pTzeWh8rpASbxRFxf3LmZ5LRIDHYNtRkCOokYCaUMxJnGJHhdjaIQ2IaIz2YkeFOGKnnM+LK5CgTmZeCzSYRLv36M0CgH/jGOUGeEZE5lHsCMEz0AKsxBOqVIthm2KtFrJtBxeq2M1Wwue3vAviGxpDqSxe93IBekUqCSYJNs/kCHi6xi0m89tqk3kVF+/I0njIx7a4q/E/X7FlQrpnSRcbnSs7LwpuViV8/unQ7xT6QkjFfq4F3S9Pw6485euoBYsocgT8YRHRhRYC5ObK4vDCwJZb8R2qCbfFcIfqC+1QBz40MiaTftzyLojtHrqJVDJioC3oRiyxMKfdUpOBFSo/dfLIpQ5VfHhBhp+iqLjaVshkZzD0HYh3nFAURWth26HmHfrQCwrtxY4KcbeATL2NhGHXJj6HuU+Tv7FAGftofnd8xH6uOUfAi237TmhN9ay7JmPkKYoyaFSgUVIvDLjGCx7twDIL7rlUNPZt5xWFhp2ucWu11cRc5eLsPAYPMwsrZKAtRy51vDN8k6uuzQLwRpsVUu/pV9m8GyzIB1pAoyF7Bj4RifgOLXC/nZPqT64LqPiWd0EceNeVYeeDHI+Rz9oKgepaznhmAXhxKAvKilW5OjGLVsWXRptV7LojAry+0G60WcVjrVaHbvP7PaGGHcNEqsIQsG2Km06/PjWd0QAMMa3YWVtT/RPut4diETGmJJqKuiK9ffOypuPiuAV/25ROQvGaxjgcOf4GZ3cXB/int4af3hpOs3Fl5xK5bddIpRUavrv4DkUUqDPqUPWunu5t74Ig/LP8aqAV1LDrBO2xxa/z5WiCzBwYZRe+ey+66HP+5uqe8XDIGIYYqt6YRCCIEe0ODY+NuDISkVaLdIh2qZEpUiu1xdk7rUTzTWZZW3iwXk7JHEuBqtGFlPJLmTmZXFGSBRFjKtLn95ca1gedWqGrGTX5C3iKooIDg3vG7bDFrtNsHOe6GC2ZPK5cUpFuVaCka1VqZC9m4a+LeZ5vB1QA+PWp6Se9fQrdeNTmHdu6GL2J6nlNvaOdaTm7p4Pq7PmNHj4qP4ysrjmCls2pXtDi7O7i5y835+aXrnZLAd4keijqOpkYrk7IZMSYxpM5BEcd0aQQ/aJ9T/OuqzmTiCrAoGVzKC5+R3urs7uLu7YSK0EpwKMOXxtoC1cChIjJi7WKf5W6SKs4woS6Rru8edc2jioQLpqNM5KsrpSfOllzY+D1F5EGPGqxalQ8W/BSpPPPly81M6lXqFAXHtCpFWlkA+FAsR0/UK8J4FHHPqBaLYCZ2XmPdjmAxXT0eGx1x7C9F7oeqZcO1KUOrqtPDPht9AOqrBiVidQ/Ui541u/oGu2paExmqSi75NfPfYxoDAM0MIF66riBthzt6z1yqUMrC299Fy2Th9r2JJa9i8S2S0podEwez6gXDGdi21EdUHHkIu7HUaxqP9fMLZnjAx7SfahR91gOKnXgZ0wZGXZEGXj9ol3esHNo3yn0K9kCWyqCh9TwV9AAwG8//Bfxj6leyIi6xR066mtbuxG64sq5TEcY5D3a9zTslKoLoXUr0G72bSxuHvXmCprEStDf9dGBoqKC0Kpmd6hYUC+N0DvalRh2jgUtFzTgy0TzoSi8i5kMtIXLzB04ePBQeXkBAB6qVU32YUjtqNpHaM9ox3NkYrKAAU/XuCFLMh9gXcwkA3it5gXlKNBAHZ5N1cKjPnQb5r5V7xe074TWQiMQw+7q6f7ZxB+gXmJhA168ihDPum++7P7wQ+yRj/rhBwHgmeYz+ahS6MBs6MxypLLlXeBPauEEkVb1iHbobefq6Xa0t0rthwWA/6rlw4KskSiH0U6oltDJ8sfXXmxvP19f5wP+4OHDKMqf8PQRQreM4NSqVNQJuu+5MNHOLvnFt12Jp97R3sr9Wap+nl3ye5tOa1LzjLQ3E7qGbSe0hu1oBvoHwLTvH168eAPwdub5s+/RvS/SRVHQGQqRicktXBFQX/sFKJU40vnr/eK3B/s/2/P7i7dN8O9LX/sF/IBH3ZsJveBWh25j+KarQ7f5jtUPL1682N5+iUY2vnS1G50pRrooqthRASUmGe0dzdqqf9N5BfrsSjz16Hq99IV26IRJaK+bzLwarQCPFPZSDUJS9kGtQ7ncc03MINKJxIvNTQ7w/q6PMhplqS3I97xDd0JrvvYL6N4U/H6pzShIm7j1hXaoGwNlXNBtE/xj+m3nFZw+PNfIgY7SQ49mKhr7quWXKK62Le/CVy2/hMaQKIqyvvNT/jqKp7eGM52BIUfgWRb8IR4IIH1qUuadXfIjigGFRsZknpcMaS00tEcmJqFmSioOxLSclQkR7YTWoEPsMPjtiEwT03IWyvEAl5HZopUFzn1tF3xtkqwBbOY9cqmDP/Rmc27+0fl2dcvp02wcdX2+q6cbShLZJb+6DDEyMek9cTrQPyB1iZQ1HUc9iEkvaE9FY1BwlnjqZQozXT3dMndhZGJSkxB9AplFkvJfgB/oa7uQS4RpJ7QG8hryv8dos3Ifw9ndxa9yBW68uvhEbd7B14H+E7Dwyz3XcvGV2CX/6tBt74nT8r+HrnGLNymo/2V1gnaplW/Qmif+o3rrk76vWj6U1LXfj3++DToyb7RZa0fu+NovQHW15V3Yaluga9xM85nDnveUcMIt70IytMb6l7e9D5XYMZAB5UcQjvb1Ll3t5uhMYiX46Hw7fypGFsIf1J1YCaIumy/x1Ff3X5eq14hMTEYmJsuajpef+OCwp37P0T2paIz1++NLy6x/eVtZAp9pOStFMQoQ7VyCB0pv9jx/rp5unKRdWwF4k4lKsEt+DrfgprPUVHNdFqx/GQzDYP0Zl4WXNR0Xr+4CZXZ8wKfZePCzGzU3BvJo6wvTclaKXQLZmJkFR9Ros4Iae341HtdRkwW3quy8iG2SqvZoj0xMQivnKInt1mJxtLduPPgLVNG6mmaloi2SsfAC002pMSnBaLNWXr7IlTwIRAx40DCnCuC5iB1qcbS3Gm3WPSsyU9GYWlotdlS81X8dJ/fU2G9nl/wyF+qehl3eoS1RwLvy18J7Zu5jOChGm7Wy86Jn5r4U1PmA57P3XGZgIBoNosTC/2ziDxjOTLGjorr/uufBfcxuppZoB4lHGQMlXm0tcygFQQ6jzaqT+dMIffjROz9904tW90S6ero9M/crOy8qcSmhgF+9NZzFW/Pn0pnwIp+ucXseKP3KWccIPA/uazJwUUsmL5ONAKdZuW2nXiUwNh78ZScUOuypr7z86zxtz8rUly5rOh6ZmIxM/FmVks8ST33ZiQ8UBvn2pPRg1RTYOZeZbV/U0s5Xdl50tLVGJiZVGZditFkPe+oVBvkKFu3yKWJx45euAh4ygn8DOSg9AI1xrH85vrS8EwrJH1OOQ4IYHu2uNjkqcr8fVQG8ifmJHqiTo73V0d66E1rbmJll/cvJ0Jp8aJML4FGvYniHPe8VOxz6cSf1uOP11QnOp1ZK67u11Og4d+K1OqBMy1lGa1UAwK/eGuZ2SK5PTT8PR4729ebjbvZiR4V8zCKPRKfTLJD2BhDBAHhndxe/tDYeCITvTmRwdRIpMLTL8EZ0TX+IhL+9LPbIRw4WRVFHLnVwBD7NxkOj4/6ujzItPdJkWQ1Bu/pikvBnXD3deWfYN+e+JKZJLOWnTvI99uii73HH5c25efn/i39dml1OosZCQDt0JAuYUZPXOiW2XQB4fhYtzcaf9PY9VZyZiy0SZarnYf393/+9hky+2FFBHThgKi8vdjiYlrPV/f/3j/7XxnzUo8lu/+t//gP48wHqAL85jAhw4PnV7+ySf/PL+cP17xlpWvzzRpp+9v/+f69CADS3popIjnJgd3eXaEEV8Z74W+7Pngf/RBQikOiiT9ADLy7IESvTZGfqxn9PtJf3TL6ABdv0lTwSW12toHI+zcYfd1zmEnVQSYYjJFBH0K4vEYSaUY+py1MxVzmd3VcFLwYHBgVuvGDQHeoWd4J2Ihka80DwTdtODihcShsbHG3nBS+G794LDgxyfxXsb0e9zp2gnUim1D3wpm1/RnQiJY72VvGAivWpaX/XR4C0R3nxPArx9G6CdiIZS+zNA0rMkbxAq2ijiz7QJCsY9UWuToJ2fQnxLTMSA20RO/DUq654QYyTXJ0E7foSQdyYgF+JA88vpOcDniiHoD2PwU8EKkcudaCeMFkYAr0Bo4s+8F8yHIGGNvxdHwlmwBmJKoloeIiZc83xQED+cowu+hIrwVyG2OpcZFZrmRjmyW/7uMG75aeaootfb859ydcYKNwsbWyI3L0XXfQ52s6XnzqZZuPmKqegCP3A7u5uaGQsEQge7esl5y9rWTz/K8H9SsrpBJIMR2KLvkQgmFgJ7olwGeHogLnKabC8DPVxnUgmhkE93CoZjmzOzXO3j9FCQ2+i9alp/pHgx3FTcVa5w2KyMwbaAn7eXOUsfb/BXOUSxzgTK8E0y6bjcYPFsvnlvK2u1tHWKvgxI0VRodFxUtedo5gYZv8kipLhCCgfSqwEn0ciiZVgdNFnoC0cgE12xsQw3Mk2WuhkJKKWfjhL+IZJfDVKJGsxVzmNFpqiqEN2xsT8xGRnDtkZcLMkVoJc/Y8UUM1VThPDgI69dDy+OTefxfcFn8FAW8wuJ/gAFpcLKHb11rCj7bzMRcZdgmk2LtVXdiD+JPC447KtrtY9+KnYVQCXVnTR9/yVb2B9txZ8As3JD3fUZB6A0UJb646Zq1y2ulqknzk4MCioADVXOTkdgmMkFnCwDDQNfkYTsppm49FFX2zRl1gJqojJghHuOaoo5adOml1O7nFjA9SB7+9/ERwYNNmZd4ZvJsMR7hMsnv+V2eU8cqnjXwcGxX5FaWNDaWNDaeP72GAPeGB08etEIJCd9sFnlmIx0UVf7JEvtvg1d+JNdsZaV1t+qkkcSQLGjbtucuGlSphqMvLseThyyM6YXU5uvjp4UaH7RwT/HQEsDSiyBC39trpaa92xZOSZvJVGiPa//uMEv0rZ0XbeQNNplg0po0aljQ3WulpwRzwPR6KLX5tdztLGBoVfJs3GpZJVgNIAhMcWfWrZHJOdKW1sKGlsAO+eWAnEFr8mOJE/sm88snicu23l9WagLWCkj4G2bM7NlzY2AKKbCATBXZnpZc2ca4498hlo2khbzC6Xucr59NaweJk0eF9r3TGpJ8t3OvhfNs3GMz1m4L0A9wYcTQ/MVxLtO38Ng6Af9+kpNRJI3JPmnxXlB4UIHiSLPQtwWafZOAgOqeUsUKLhnOCijz3yAZICAAPiT7a62scdl8XXwZFLHeIUfWIlyA0OMtkZcAuAv27OzYs9uMRKcP2L6WQ4Aq4e67u1XGBvc24evDv/h1Nx1sQw4jYnDOFA9dG+u7ubZuPhuxOhnOMchSEG2nK0rzf2yBf+0z1saXNbXS0XfRBbHoBMhYFcDsbi+9RkZ5hfNNtecTGdBwIXz/9K/Lqzu4tElHNCO/jTk94+kFfY80jZzzVb62o35+blO5O1DZYAcgHCYGIiKhOO4s5Tmo1vzn2ZCAS/n5rmrFNG+OdC04DggCirjFng4gUcUPmhO2DEDDS9/sU0eN1gsYDM0541KsCQ5lcpy7+c/Tuoto/29ZJpNrmiHVh4R3srSL+XNjZwCQCp/xlEtta/mEmGIyY7k2JZk51Js/EUy1pcLuVcvfzUyTTLQocTmqucZpcLhMqg7A5YKhDNCv/pnpGmSxsbyn9+Uon54iJz3EctbWyA1h1EF31GC73+xbRU8B98AI4fiXMcRDIVbnwNn/hQshNviChFe9YCUov2c83RRR/fenBZ2dgjH9+igsC4gbaAaY2lje9zTw6gDhBR8eMEWcfNuS9/fOpkSWOD+CbKuuKKy0KJCxKUS2Il+LjjMkG7KhJd9Pm7PuK4ZPnPT3K6JYDXEu1EgITv3uOyG1IcgYhC4QfbHW3nHe2tgvC7ucqZXyvi9SCkK0Y12eJ5ImQKeu62XfCKo62VH+zIZWM0QTsRIjoSfnzEQNOAvR/9hzdmYCRWgsGBG0RXBO1ECkc4/xwMseQDfnNunj/QjghBuwZClkOphXCBlDY2COJz61PTgi5uIgTtyOVQvlVW5YsIav7MVc4jlzr4gA+NjuMs/SBoJ0LZ3qwnJ5KLlL7fIGPnbXW17wzf5BfViXsQiRC0oxIw4YD7K3/BM5FMJbESFMzwhYqzu4t/EazeGiYz7QjacUhodJyPdpIHzk2ZYwoLMfkZuDQbF8+rJULQrr6QxcMqCv/elO8zE6ydSbPxJ7/tI0l4gnbkTJ4oAYVwE6+gUn7qpKDVJxmOkKobgnZ8QqYm45Sjfb2CMB4psyNoRyukQ0NFySjqAe2QIWV2BO0o0U6C8OoJP6NhVZDXBIAXTLkgZXYE7ejQTmy7amLNvHLBQFuc3V3O7i4+L1ifmiaAJ2hH66uTorpc0Z5t3XH5qZPiuloCeIJ2hH67YDYWkVyYfBYPQsDqCeAJ2lWW9alpUlGjlnAzZLMTwOqPXOoggBdI4W99XO65lgytvT4KNqu9+UxZ03F13yURCJKUj1oSVVA2u/fJpi38qaGgit7Z3UXQXrCyE1qLTEwKXtyYmfU8uF/sqFCTyZMonXqiiitUfuqkgaaDAzcI4PcLkxdD/dUtEFL3jUhkTocCmuFJlH6/o111AfNziehNxMMq9zPgCxnt7JJ/h+exEyGA3+eAL2S0R+79Gfp6saOixFNPYLCvAF/JC9HvW8AXNNolaDzTclb190rHSUBePbdIjZi8QMpPnTza17vPLXzBon1jZjYVjUH/ydHWqvrbkY5X/WuytLFBsAtovwG+YNG+/uAvUobdaLOq/nbQJXZEskF7JIJu27f9XLOgUG99aprb8FPwon6+PTIxyfqXd0JrtLuaaTmrblo7A9v+YFYC7WcIovQs8uMrcpcjlzoE3e/hu/fMLud+WBRdpDrUl3uuhUbGNmZmV4due0+cDvQPSDFq/DSernEjis+RslnV0I64cgG6QG6fjKxV2baL+XNoZGzb+7B25A4K/pwpjReMMVNRMtpgjV9S0Rjr91MUFV9aTsViFEUd9rxHUZQ+cxMmO4M0DgIAH/zsBn9kJXDgM7LwO6E1UKa17X1IUZTRarXUVButVrrGvS/QnoZZVHbJ/1XLL98e+hybFqA03mizoojGAzlkZ6hFfT3andDaxszs1sLDbe+CDL2ia9xM85mypuNa+VxQMo866vkS8AM3+AGX4MCggaZLGxtk/kd2yb/x4C/b3odb3gWZHytrOl5+4oOyE8dxGjkN/Hapk/fdx714LLwUjUcHdUpnXa6RicnQ6Di75Ffyw+ySn13yB/oHmJazrp5uPZxOa90xDETJQFuO9vWGRsZCo+M8wN+AboZPRWOh0bHIxKTCeq2NmdmNmVmjbcDR1lrZebEw/XZnz2+kjgu75Pe1X8Dgw0vT+FaEB1Qfi982Zma9J04v91xTCHXBHeFtOq2HnWpgqSsexTraW/l5eOhQ+tWh296m06tDtzMtzUxFYyB6JU8E8hXtdI1bxoCzS/7lj69pQuNRM1XxBmL8nvk3nVe+6bySS7FwKhoL9A9803kFf2D1tTOIvXFY0DyTZuPBz152zrFL/q9aPlwdup2LQnZCa762C6tDtwsN7QDwrp5uGeOD9GtL0Xh08bmXhvFP9/g+IeanuOVd8Dad3piZVUuHvvYLWbADtQg2X5l4RFBaC2ZUh0bGvmr5UC09rA7d1vYapRBV1zAtZ6v7r8t8bbXOpUIaj6EwvvznTVo9wtDImK9NZRcJuF1aAZ4fJ0OdfucFC2r575tYCT793X9U3RThcWalBFWUDoTElnvgvH3542seTz2KgBCUxiP12F8ZBxf+Awo0vGdXb4mn3uSo4DsyrH85vleDYCoa87VfqB25gz+fZLC8ToabcA0OMNmZo329/Fpag9m8++JFimUhsLFZabcb5Nu4F7e9D1m/Xx7M4BrFnJBGjnYA+C3vQ+hZTEVj33ZeqR29g4HGI028SZ0bPUC9xFPPtJyRSQKxS/7Q6LjMb0hFY9gyKdpq8rXSGv6Xg2WlLzY2Xx6ew4d/ePHih2SSf6rLT3wgM+lsY2Y2NDouE5YDGRAZ8ptnTJ6T6v7rUkjb8i6oHv6F0ng8Oc/ESgCz0746dFsKqMWOitrRO7Wjd+SbAugad3X/dc+D+zJuDp7AqiTaGdxo/7bzSsz3+MXmJvfKoR/96EBREbg9PQ/uV/dflx9qWNZ0HChfJiocmZjUJPeBvCtGRjurN2+rOG0iFY1BTz/mbCeeAxqZmJQKdjraW+UBDL0a5AOrmI9mIhDEfHVyXAnY5HQi8RrwRUUHf/Sj6v7r8gAWE6ufTfxRhlQG+gfwh0Vw9MBVf3Id6vulorHvelSzG1CPvcRTj7lEDMM4SkAFpe5WGdzKiKO9tXZUkrFjPppcEg7nbM/IxCTfWqQTiXQi8RIkJtPmf/0yfPdeRhV+RptV/nF8iz1EjwPtRptVKtijIp+H0njUiTdIhAl9sv27j3uhp0TGb1JojmRc9GD/Zxh1iLvFaCe0Jr5AX2xucoCPLvqe3hp+3HE503IAR3urlIu+E1oLjY4VGtoB4N/6pA96klTh86AmXMxRVZ8bLyXcuJWnt4YFlViqu+tQM+vq6c49GAmKo6Ti5GbYjwAAD5JJREFULNhGenKIWr01jGdMyHc916AX6LH/NMzvkwGVdpkCHpQkSz1NnKMT8U2zkCqzU4XPQxP4mEPxr79RnEVngqDWoKzpuKO9Va3HJGWLciwpUy7JSIRDF/dndLIxMwsNobt6uukad+WlDn74ABTeZHqhO9pbpU6jlFOW32inpMvstrwLOdbbQAdOYkizYxYo3ow2a/UnaqZzmJaz0KOJjXliHvsFxVuJpx5coOL98ADwmU4rAneH8rsm79EOThI0SL788bWs7Qbo4hK/kVZZYkSV3tC9N+AYqf5NXT3d0OgmHrTzF+aiFqm2trd4BEcM+DQbf9Lb5+/6SPmzBs4s9J/4TXgFhXaKoio7L4pNRyoayzqvC1UW/vgcz4dH0q0JTbmVeOpROCxGm/UtGJ+XSnOiE6RBECmtVnZeFFx2YsBTFBVd9PE3TynhtlBTtzEzi8d712YKJZTVZEdpUtGYOPdG17g1nB+CYiKllGE/0vlrRN9C6h7B3Mu1hXK8J9SwG21WqA8IBfzm3HxGcTvxPYJTq9qgHeTkxPxTKjQqF2J5AKmWxW/Y+YcAWlmd+7kUv4i626ey86L4Ge2E1nB2ayON0kUmIOEemeJLKOATK8HVTKbWQkNX0GNcIGjnAC8+Sas3M7vkxDQef2E89WYjBwq/XZMywWJHBdTKQUGC6OpEV5sodW3Ja9VAW94ZvikYX5fRmOqypuPiOxpKUQsH7ZREiD40MqbcdEDjc5qE4vlFNaoXh0D9OqPNWnYCeTWBo61VbOgiE5NIDRH/6kQn0IijwuJLZ3eXAPDhu/eUe3BQ/wtDrE7j7RHQPKRyPg9VkCZpdr45EuwnUMF3XXiYEeFUl4JB9YnUEOEZ/gMGxYoOj9J1A87uLsEq+ODADYUxxRJPvTiuhGFJqfa7YsQRO4V8Hhof1mp2qtGC1raLXyw/8QGmGxnGlaSG/6l+dVrrjiGi8dCSxIzokmC3HH/ElQKtnlf4oAsK7dA8pBI+D2ViWiXe+AdU3V6OndAa9MrHVhQMLUCWWbOn7tWJqMV9G3a6SjKfsAJm2nEfUnnEDloPIrWVuHDQLuXAy/N5MPFXfC41XIfA3fHqjkmVOpc4v5q9+QxOMs+/Og+hQfsWjMaDjRpZfNp3hm9yn1n5Jkmxi4SazOtl66OjvVVwgndCazL1NqHRMfFdoO3gbs5d55smXZ3LrAXqH0E/mFrCWUtEdXXQOzRrrQoC9QoBD3WRtlFmN3W04/Xtoc8F3GZjZlZq0JXYsOOJUcsIZ4XUncEQ9y9rjnao44A0UId0KEgqGoOa0BwZk7O768irwbUA8PI+fLGjQhyrQxoQ0RHaod0d0DkKUMOu+RYebl2Muvl2aDCJduOuFGREZD4VjaEbcYF0ag1YiSd2J1Vwec41uwc/BT7d+tT0447L61PTMudBrNX9YtuBARHYEDAIkY9tqGHXnMZTvLGz8UBAPRq/ALUJ+O81usYtJvPbyMg8l3JH0Q8H/dgWd7Uqv9xWV8vV2yXDkeDAoExprZgxIb1D9YV2iqKqP7kuOMqClVJQw45/IhXUeXvF4mbU+p3QLZrFDocmX/CwiOhCCwFUES7SiWLRMthyK75DVSQmNTcGuIgD6JCFAr74zcnfqO9Q3aHdaLOK4/Mc4KVarNE1hygXLkq3PjWtlkViYU67paZaky8ozvDH0Q+rCyPYGxNfWoY5R2pq1UBb3IOfcnE7GcCLzTv0oRcm2imKYlrOiuMlAPCB/gGxYYf+vIa2nUI8CJ2/sUBb274TWkOUdecMI7a1cAYEzhE/bpdYCT463y4utiupFwZc4/sK7RRFOXt+AzF0S35xsZH82jmckmbjHODVWkgMJXXqWqGMaBek3tOPxLwjbWuHRkMQBT5/fOokB3joAtnDMMO2v9BO17gVlrtLDbfEL9FFHx5DZNDu+4pDWVBWrIoy8d9liBjfj0+dlNkYbbRZxa47IsDrFO2Ushh7ZedFDadWiMxRgCp0EdOKnTUktV9pli0YpRloC3+BrBjwFtEZTqKpqNMv2osdFXuad13NmcS2tEyrmDwFCxAisu1vHH30QylRJ3TKT518Z/gmd0IA4LkOWfEdiihQp1+072neS9Bsic1arLhmJ2qYa4SMYYghidKVNr7/Gu0RDGhHfoGCcnouSg/mWIL8orgyEpFWdY12nOsf8si2ayviaghE2Cg81Rloi7O7i9+mGRwYXJ+aFidZEDGmIp0rCFsXtyqEkwvGoJ6UqqnrjiNQUsAKtJ9rcQ9++s7wTXBaggOD2yj7i/IJ7TIj0BDlfnKx7f/z5D8CC19IQaY9BYV5N1c5PQ/+qSDVZaAttrpac5Xz3fERQGFCo+MHS0sxnG1do33LuyAz0yIVjeEcfqoU86o2b0HL5jAvBhV+QVHUAJGTyUnskcrZOHEeB/VXkII9V1FvMJv5gEf0iHWN9qdDv8vxB/LeSYaVzWlLanDGCBE1t4u1in+VOh/w4GsKAL+/0C5v2LmfUWshtMo+fOQZRYSIMsC7Bz/9N5VHAOAPlZcfKCrad2hXaLdXb97W6mKWcjgpinquUooYOrUirSmTLwCBalVb/2g3lQK74otMJnSA1ynalRh27iH52i/oB/AYZqGj65FSItgCyNSrcUB4iJK2/tGWd+HF5mZqe5uiqAMHDx4qL0dRha1TtEM3ukul3/UGeBUF2tuHZ0OgHgSMA3qudi0d1LYndaDVFMu+2NwEgM9ovVweox26i4+ucf9s4o8/HfocWk4LAI96HLcyJq/y6ghxVCyuqW0Xcy78Y7NyVqlDV4yJr9J0IvH82TPqhx9kWuILCu3ifZdGm5WbUSm19T4VjX3TeQXzBlIIk1d7dYQFtlREKycTSqDQ1S8jKk+EjvrC6aEIr+83K+d+ePGiyGQy2RnVAV+kQ6iLDbujrZUzcTJb78H/vtxzTcPPr+54aUqim31bo0ID1OsNoH47ChHzEQ3vULFWD/3kx2BGfWIlGBy4UZhol5owKeh1k59gEZmY1BDwqhd4l8Fqh5HOIZYRzL6S6lenvFYxbFmFRmGgjImbUb85N69wHUWeoX315m3oICox7xJvmxAAPtA/QBWE0DVu8dfHs+5bYTwlj65OTqCBOtSbqhX6rRSvhhLMugIbo3PvHdAR2ndCa9BSGam1m+JtE3wJjYxpFbRTvQJMvBUDz7pvwTtCL1Cm+QzS91U9DsJdUrDtNwuY8x1b3gXofhS+VsGM+u+nph93XF48/6tcuv11hHboYZJZ7QZCd5n+wnz0NqGNgJjjkcsfQ9bySe17VlEsLhciwEOzuTi1morGoJlm8b5nW10taKFJhiO5jNzWC9o3Zmahpviw7DDZEk+9zMQLKY8ItZiYn6TirLrnUmyIdkJr2I5moH8A+nQcba2oB4qYq5yI1rlDBx9FJiaxtVr52i9AqQR0XDqoqKcoKjQ6njXgdYF2dskvteBxz/52+dF0mvQ2Wd+tTawE1S3gh15qq0M4qoZXh25Dv4vRZsUwKczscq5PTYfvqj9VXmoUmvxyYbWs+jedV6DPrsRTL0Vmk+EIcBKDA4PZTenUHu2paOzbzitS+lUyu0begccsaTYOar9ii1+r+GuZlrPQ5jMp+6DWo1nuuSbFICovX0St9jQbT7FxiqKeoxlWBb1Dd0JrvvYL6L4U+P1SQSXobHWO5rgHPz3a12uyM5G797LIw2uP9m87r0idV4VjqoodFdCEnNFmxb9VwkBbQqPjFEVVtJ/HcDRT0dhXLb9EYeG3vAtftfwSGkMCJsjRjmMEKMjIljQ2oPjlUuadXfJ/1fIhCgsfGhmTeV5KZiiXNja8M3zTQNOPzrdnyh81RvtyzzUZN0m8RkPG9ImvBq0m0paiOZpSK3FUrxre8i742i742iRZQ7GjQj4+quLVCcZRoku8u3q6oQwF7CZS8RqNTEx6T5yGLjvibJvCzaVgvl3lpY7Q6Li/6yPlRv7A7u6uVlAPjYzJh809D+4rn50ArBx3QJmWs9X91zX5XomV4JPf9tWN/x4FtfY2nZY6LiWe+iOdv86azuyE1ra9C6HRcfkjbrRZa0fuYBvjvzk3Hxode2f4Jrq3ALebzCVb2Xkx6xke7JJ/48FfoKUKfKFr3LUjdzL1jEBprcnO1NwYUJK50BLt3hOnZVRA17h/NvGHTM9rfMm/E1o77HlP260S/3L274729aIYvSLYeAvVG9N8RqEGtrwLydAa61/e9j5UYsfoGvfbQ5/jHF+TZuP/cvbv6sZ/j3Sk7571l2VNx8tPfHBYwSrhVDTG+v3xpWXWv7ytLIHPtJyVohjqAl5LtP+zu1aeYuHxDFGIv+sja90xRJ9/y7sgE9cUWHuKoiw11dxsJta/DIZhsP6My8LLmo6L921jkMXzv2J+0Ww/16wt0+SoDaix51fjcR01WWTvKjsvKiTwuQNep2g32qyemfu6Wg6RkTzp7Uuzcffgp4h+/54WXl0x2qyVly9qdfkivTozsvDqSrGj4q3+66oEkgHg+RsmoaJllE4GzBjKNpCK2YV2+QFd4/bM3MeQcTDarJWdFz0z9/OXZykXpuXszyb+gMFPKXZUVPdf9zxQ7Qmaq5w1NwaS4ciT3j6dol1qCgJd49bVgjd9itFmrR2981NkXjTIa3pm7ld2Xszrmzfja/QBwq9c4qkHOFe94thc5WT2cnaMGmrWUlMt9nNAdiffj1c6HsfzRmVNx8uajkcmJiMTf1al5LPEU1924gPNw5wCUbdUSYkv7WhrjUxMhkbHci9eMtqshz31CoN8uYitrvZ5OPKkt+/IpQ5oUFNLv30ntOZr+/d8beYSnNSb315+6iSixLuUgMY41r8cX1reCYXkjynHIUEMj3ZXmxwVukK4tsrkn9KNmVnWv5wMrcmHNrkAHvUqhnfY816xw4F5S2doZCw0Om4/1+xoaxUE7bS07cWOCs+D++ySH1Sz4697QyeIGjn2tCFMy9l9sXoS7ynNr5iFo701GXkWvnsvsRIUxImNmn84fdqTXJk8y2pliwpPkpEIUWZG4uzuSgQC1rpjgteLiGpQyObcfC59yET4klgJZtfytZ8FtMduzs0TtGMCPFGCKlCnECx+LHgBLQaJlUAyHAnfvff01jClbZSugA/o5tyX5ioX4Z+qXJqJlYD13VpEGyALW6KLvjQbN9CWNBtPs6yRaER1ScXZRCC4H8pRsFydgWTkmYNAPSvhX5HJcIQweSRiratFscdrP2ry3Vqzy0mUmbuY7AxBO5IL1VZXu3S1m7juqijTXOUkylRFiN+O1mUirrsqsj41fcjOENc9R/n/AZQE7sYZBxvKAAAAAElFTkSuQmCC\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tic-tac-toe is a nice testbed for reinforcement learning techniques. The game is simple enough that exorbitant amounts of computational power aren’t required to train effective agents. At the same time, despite tic-tac-toe’s simplicity, learning an effective agent requires considerable sophistication. The TensorFlow code for this section is arguably the most sophisticated example found in this book. We will walk you through the design of a TensorFlow tic-tac-toe asynchronous reinforcement learning agent in the remainder of this section.\n",
    "\n",
    "# Object Orientation\n",
    "\n",
    "The code we’ve introduced thus far in this book has primarily consisted of scripts augmented by smaller helper functions. In this chapter, however, we will swap to an object-oriented programming style. This style of programming might be new to you, especially if you hail from the scientific world rather than from the tech world. Briefly, an object-oriented program defines objects that model aspects of the world. For example, you might want to define Environment or Agent or Reward objects that directly correspond to these mathematical concepts. A class is a template for objects that can be used to instantiate (or create) many new objects. For example, you will shortly see an Environment class definition we will use to define many particular Envi ronment objects.\n",
    "\n",
    "Object orientation is particularly powerful for building complex systems, so we will use it to simplify the design of our reinforcement learning system. In practice, your real-world deep learning (or reinforcement learning) systems will likely need to be object oriented as well, so we encourage taking some time to master object-oriented design. There are many superb books that cover the fundamentals of object-oriented design, and we recommend that you check them out as necessary.\n",
    "\n",
    "# Abstract Environment\n",
    "\n",
    "Let’s start by defining an abstract Environment object that encodes the state of a system in a list of NumPy objects (Example 8-1). This Environment object is quite general (adapted from DeepChem’s reinforcement learning engine) so it can easily serve as a template for other reinforcement learning projects you might seek to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-1. This class defines a template for constructing new environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "  \"\"\"An environment in which an actor performs actions to accomplish a task.\n",
    "  An environment has a current state, which is represented as either a single NumPy\n",
    "  array, or optionally a list of NumPy arrays. When an action is taken, that causes\n",
    "  the state to be updated. Exactly what is meant by an \"action\" is defined by each\n",
    "  subclass. As far as this interface is concerned, it is simply an arbitrary object.\n",
    "  The environment also computes a reward for each action, and reports when the task\n",
    "  has been terminated (meaning that no more actions may be taken).\n",
    "  \"\"\"\n",
    "  def __init__(self, state_shape, n_actions, state_dtype=None):\n",
    "    \"\"\"Subclasses should call the superclass constructor in addition to doing their\n",
    "       own initialization.\"\"\"\n",
    "    self.state_shape = state_shape\n",
    "    self.n_actions = n_actions\n",
    "    if state_dtype is None:\n",
    "      # Assume all arrays are float32.\n",
    "      if isinstance(state_shape[0], collections.Sequence):\n",
    "        self.state_dtype = [np.float32] * len(state_shape)\n",
    "      else:\n",
    "        self.state_dtype = np.float32\n",
    "    else:\n",
    "      self.state_dtype = state_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic-Tac-Toe Environment\n",
    "\n",
    "We need to specialize the Environment class to create a TicTacToeEnvironment suitable for our needs. To do this, we construct a subclass of Environment that adds on more features, while retaining the core functionality of the original superclass. In Example 8-2, we define TicTacToeEnvironment as a subclass of Environment that adds details specific to tic-tac-toe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-2. The TicTacToeEnvironment class defines a template for constructing new tic-tac-toe environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeEnvironment(dc.rl.Environment):\n",
    "  \"\"\"\n",
    "  Play tictactoe against a randomly acting opponent\n",
    "  \"\"\"\n",
    "  X = np.array([1.0, 0.0])\n",
    "  O = np.array([0.0, 1.0])\n",
    "  EMPTY = np.array([0.0, 0.0])\n",
    "  ILLEGAL_MOVE_PENALTY = -3.0\n",
    "  LOSS_PENALTY = -3.0\n",
    "  NOT_LOSS = 0.1\n",
    "  DRAW_REWARD = 5.0\n",
    "  WIN_REWARD = 10.0\n",
    "  def __init__(self):\n",
    "    super(TicTacToeEnvironment, self).__init__([(3, 3, 2)], 9)\n",
    "    self.terminated = None\n",
    "    self.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first interesting tidbit to note here is that we define the board state as a NumPy array of shape (3, 3, 2). We use a one-hot encoding of X and O (one-hot encodings aren’t only useful for natural language processing!).\n",
    "\n",
    "The second important thing to note is that the environment explicitly defines the reward function by setting penalties for illegal moves and losses, and rewards for draws and wins. This snippet powerfully illustrates the arbitrary nature of reward function engineering. Why these particular numbers?\n",
    "\n",
    "Empirically, these choices appear to result in stable behavior, but we encourage you to experiment with alternate reward settings to observe results. In this implementation, we specify that the agent always plays X, but randomize whether X or O goes first. The function get_O_move() simply places an O on a random open tile on the game board. TicTacToeEnvironment encodes an opponent that plays O while always selecting a random move. The reset() function simply clears the board, and places an O tile randomly if O is going first during this game. See Example 8-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-3. More methods from the TicTacToeEnvironment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(self):\n",
    "  self.terminated = False\n",
    "  self.state = [np.zeros(shape=(3, 3, 2), dtype=np.float32)]\n",
    "  # Randomize who goes first\n",
    "  if random.randint(0, 1) == 1:\n",
    "    move = self.get_O_move()\n",
    "    self.state[0][move[0]][move[1]] = TicTacToeEnvironment.O\n",
    "def get_O_move(self):\n",
    "  empty_squares = []\n",
    "  for row in range(3):\n",
    "    for col in range(3):\n",
    "      if np.all(self.state[0][row][col] == TicTacToeEnvironment.EMPTY):\n",
    "        empty_squares.append((row, col))\n",
    "  return random.choice(empty_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility function game_over() reports that the game has ended if all tiles are filled. check_winner() checks whether the specified player has achieved three in a row and won the game (Example 8-4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-4. Utility methods from the TicTacToeEnvironment class for detecting when the game has ended and who won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_winner(self, player):\n",
    "  for i in range(3):\n",
    "    row = np.sum(self.state[0][i][:], axis=0)\n",
    "    if np.all(row == player * 3):\n",
    "      return True\n",
    "    col = np.sum(self.state[0][:][i], axis=0)\n",
    "    if np.all(col == player * 3):\n",
    "      return True\n",
    "  diag1 = self.state[0][0][0]           + self.state[0][1][1] + self.state[0][2][2]\n",
    "  if np.all(diag1 == player *           3):\n",
    "    return True\n",
    "  diag2 = self.state[0][0][2]           + self.state[0][1][1] + self.state[0][2][0]\n",
    "  if np.all(diag2 == player *           3):\n",
    "    return True\n",
    "  return False\n",
    "def game_over(self):\n",
    "  for i in range(3):\n",
    "    for j in range(3):\n",
    "      if np.all(self.state[0][i][j] == TicTacToeEnvironment.EMPTY):\n",
    "        return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our implementation, an action is simply a number between 0 and 8 specifying the tile on which the X tile is placed. The step() method checks whether this tile is occupied (returning a penalty if so), then places the tile. If X has won, a reward is returned. Else, the random O opponent is allowed to make a move. If O won, then a penalty is returned. If the game has ended as a draw, then a penalty is returned. Else, the game continues with a NOT_LOSS reward. See Example 8-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-5. This method performs a step of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self,      action):\n",
    "  self.state =      copy.deepcopy(self.state)\n",
    "  row = action      // 3\n",
    "  col = action      % 3\n",
    "  # Illegal move -- the square is not empty\n",
    "  if not np.all(self.state[0][row][col] == TicTacToeEnvironment.EMPTY):\n",
    "    self.terminated = True\n",
    "    return TicTacToeEnvironment.ILLEGAL_MOVE_PENALTY\n",
    "  # Move X\n",
    "  self.state[0][row][col] = TicTacToeEnvironment.X\n",
    "  # Did X Win\n",
    "  if self.check_winner(TicTacToeEnvironment.X):\n",
    "    self.terminated = True\n",
    "    return TicTacToeEnvironment.WIN_REWARD\n",
    "  if self.game_over():\n",
    "    self.terminated = True\n",
    "    return TicTacToeEnvironment.DRAW_REWARD\n",
    "  move = self.get_O_move()\n",
    "  self.state[0][move[0]][move[1]] = TicTacToeEnvironment.O\n",
    "  # Did O Win\n",
    "  if self.check_winner(TicTacToeEnvironment.O):\n",
    "    self.terminated = True\n",
    "    return TicTacToeEnvironment.LOSS_PENALTY\n",
    "  if self.game_over():\n",
    "    self.terminated = True\n",
    "    return TicTacToeEnvironment.DRAW_REWARD\n",
    "  return TicTacToeEnvironment.NOT_LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Layer Abstraction\n",
    "\n",
    "Running an asynchronous reinforcement learning algorithm such as A3C requires that each thread have access to a separate copy of the policy model. These copies of the model have to be periodically re-synced with one another for training to proceed. What is the easiest way we can construct multiple copies of the TensorFlow graph that we can distribute to each thread?\n",
    "\n",
    "One simple possibility is to create a function that creates a copy of the model in a separate TensorFlow graph. This approach works well, but gets to be a little messy, especially for sophisticated networks. Using a little bit of object orientation can significantly simplify this process. Since our reinforcement learning code is adapted from the DeepChem library, we use a simplified version of the TensorGraph framework from DeepChem (see https://deepchem.io for information and docs). This framework is similar to other high-level TensorFlow frameworks such as Keras. The core abstraction in all such models is the introduction of a Layer object that encapsulates a portion of a deep network.\n",
    "\n",
    "A Layer is a portion of a TensorFlow graph that accepts a list in_layers of input layers. In this abstraction, a deep architecture consists of a directed graph of layers. Directed graphs are similar to the undirected graphs you saw in Chapter 6, but have directions on their edges. In this case, the in_layers have edges to the new Layer, with the direction pointing toward the new layer. You will learn more about this concept in the next section.\n",
    "\n",
    "We use tf.register_tensor_conversion_function, a utility that allows arbitrary classes to register themselves as tensor convertible. This registration will mean that a Layer can be converted into a TensorFlow tensor via a call to tf.convert_to_tensor. The _get_input_tensors() private method is a utility that uses tf.convert_to_tensor to transform input layers into input tensors. Each Layer is responsible for implementing a create_tensor() method that specifies the operations to add to the TensorFlow computational graph. See Example 8-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-6. The Layer object is the fundamental abstraction in object-oriented deep architectures. It encapsulates a part of the netwok such as a fully connected layer or a convolutional layer. This example defines a generic superclass for all such layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "  def __init__(self, in_layers=None, **kwargs):\n",
    "    if \"name\" in kwargs:\n",
    "      self.name = kwargs[\"name\"]\n",
    "    else:\n",
    "      self.name = None\n",
    "    if in_layers is None:\n",
    "      in_layers = list()\n",
    "    if not isinstance(in_layers, Sequence):\n",
    "      in_layers = [in_layers]\n",
    "    self.in_layers = in_layers\n",
    "    self.variable_scope = \"\"\n",
    "    self.tb_input = None\n",
    "  def create_tensor(self, in_layers=None, **kwargs):\n",
    "    raise NotImplementedError(\"Subclasses must implement for themselves\")\n",
    "  def _get_input_tensors(self, in_layers):\n",
    "    \"\"\"Get the input tensors to his layer.\n",
    "      Parameters\n",
    "      ----------\n",
    "      in_layers: list of Layers or tensors\n",
    "        the inputs passed to create_tensor().   If None, this layer's inputs will\n",
    "        be used instead.\n",
    "      \"\"\"\n",
    "      if in_layers is None:\n",
    "        in_layers = self.in_layers\n",
    "    if not isinstance(in_layers, Sequence):\n",
    "      in_layers = [in_layers]\n",
    "    tensors = []\n",
    "    for input in in_layers:\n",
    "      tensors.append(tf.convert_to_tensor(input))\n",
    "    return tensors\n",
    "def _convert_layer_to_tensor(value, dtype=None, name=None, as_ref=False):\n",
    "  return tf.convert_to_tensor(value.out_tensor, dtype=dtype, name=name)\n",
    "tf.register_tensor_conversion_function(Layer, _convert_layer_to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding description is abstract, but in practice easy to use. Example 8-7 shows a Squeeze layer that wraps tf.squeeze with a Layer (you will find this class convenient later). Note that Squeeze is a subclass of Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-7. The Squeeze layer squeezes its input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squeeze(Layer):\n",
    "  def __init__(self, in_layers=None, squeeze_dims=None, **kwargs):\n",
    "    self.squeeze_dims = squeeze_dims\n",
    "    super(Squeeze, self).__init__(in_layers, **kwargs)\n",
    "  def create_tensor(self, in_layers=None, **kwargs):\n",
    "    inputs = self._get_input_tensors(in_layers)\n",
    "    parent_tensor = inputs[0]\n",
    "    out_tensor = tf.squeeze(parent_tensor, squeeze_dims=self.squeeze_dims)\n",
    "    self.out_tensor = out_tensor\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Input layer wraps placeholders for convenience (Example 8-8). Note that the Layer.create_tensor method must be invoked for each layer we use in order to construct a TensorFlow computational graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-8. The Input layer adds placeholders to the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Layer):\n",
    "  def __init__(self, shape, dtype=tf.float32, **kwargs):\n",
    "    self._shape = tuple(shape)\n",
    "    self.dtype = dtype\n",
    "    super(Input, self).__init__(**kwargs)\n",
    "  def create_tensor(self, in_layers=None, **kwargs):\n",
    "    if in_layers is None:\n",
    "      in_layers = self.in_layers\n",
    "    out_tensor = tf.placeholder(dtype=self.dtype, shape=self._shape)\n",
    "      self.out_tensor = out_tensor\n",
    "      return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_tf.keras and tf.estimator_**<br>TensorFlow has now integrated the popular Keras object-oriented frontend into the core TensorFlow library. Keras includes a Layer class definition that closely matches the Layer objects you’ve just learned about in this section. In fact, the Layer objects here were adapted from the DeepChem library, which in turn adapted them from an earlier version of Keras.<br>It’s worth noting, though, that tf.keras has not yet become the standard higher-level interface to TensorFlow. The tf.estimator module provides an alternative (albeit less rich) high-level interface to raw TensorFlow.<br>Regardless of which frontend eventually becomes standard, we think that understanding the fundamental design principles for building your own frontend is instructive and worthwhile. You might need to build a new system for your organization that requires an alternative design, so a solid grasp of design principles will serve you well.\n",
    "\n",
    "# Defining a Graph of Layers\n",
    "\n",
    "We mentioned briefly in the previous section that a deep architecture could be visualized as a directed graph of Layer objects. In this section, we transform this intuition into the TensorGraph object. These objects are responsible for constructing the underlying TensorFlow computation graph.\n",
    "\n",
    "A TensorGraph object is responsible for maintaining a tf.Graph, a tf.Session, and a list of layers (self.layers) internally (Example 8-9). The directed graph is represented implicitly, by the in_layers belonging to each Layer object. TensorGraph also contains utilities for saving this tf.Graph instance to disk and consequently assigns itself a directory (using tempfile.mkdtemp() if none is specified) to store checkpoints of the weights associated with its underlying TensorFlow graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-9. The TensorGraph contains a graph of layers; TensorGraph objects can be thought of as the “model” object holding the deep architecture you want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorGraph(object):\n",
    "  def __init__(self,\n",
    "               batch_size=100,\n",
    "               random_seed=None,\n",
    "               graph=None,\n",
    "             learning_rate=0.001,\n",
    "             model_dir=None,\n",
    "             **kwargs):\n",
    "   \"\"\"\n",
    "   Parameters\n",
    "   ----------\n",
    "   batch_size: int\n",
    "     default batch size for training and evaluating\n",
    "   graph: tensorflow.Graph\n",
    "     the Graph in which to create Tensorflow objects.   If None, a new Graph\n",
    "     is created.\n",
    "   learning_rate: float or LearningRateSchedule\n",
    "     the learning rate to use for optimization\n",
    "   kwargs\n",
    "   \"\"\"\n",
    "   # Layer Management\n",
    "   self.layers = dict()\n",
    "   self.features = list()\n",
    "   self.labels = list()\n",
    "   self.outputs = list()\n",
    "   self.task_weights = list()\n",
    "   self.loss = None\n",
    "   self.built = False\n",
    "   self.optimizer = None\n",
    "   self.learning_rate = learning_rate\n",
    "   # Singular place to hold Tensor objects which don't serialize\n",
    "   # See TensorGraph._get_tf() for more details on lazy construction\n",
    "   self.tensor_objects = {\n",
    "       \"Graph\": graph,\n",
    "       #\"train_op\": None,\n",
    "   }\n",
    "   self.global_step = 0\n",
    "   self.batch_size = batch_size\n",
    "   self.random_seed = random_seed\n",
    "   if model_dir is not None:\n",
    "     if not os.path.exists(model_dir):\n",
    "       os.makedirs(model_dir)\n",
    "   else:\n",
    "     model_dir = tempfile.mkdtemp()\n",
    "     self.model_dir_is_temp = True\n",
    "   self.model_dir = model_dir\n",
    "   self.save_file = \"%s/%s\" % (self.model_dir, \"model\")\n",
    "   self.model_class = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The private method _add_layer does bookkeeping work to add a new Layer obect to the TensorGraph (Example 8-10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-10. The _add_layer method adds a new Layer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_layer(self, layer):\n",
    "  if layer.name is None:\n",
    "    layer.name = \"%s_%s\" % (layer.__class__.__name__, len(self.layers) + 1)\n",
    "  if layer.name in self.layers:\n",
    "    return\n",
    "  if isinstance(layer, Input):\n",
    "    self.features.append(layer)\n",
    "  self.layers[layer.name] = layer\n",
    "  for in_layer in layer.in_layers:\n",
    "    self._add_layer(in_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers in a TensorGraph must form a directed acyclic graph (there can be no loops in the graph). As a result, we can topologically sort these layers. Intuitively, a topological sort “orders” the layers in the graph so that each Layer object’s in_layers precede it in the ordered list. This topological sort is necessary to make sure all input layers to a given layer are added to the graph before the layer itself (Example 8-11)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-11. The topsort method orders the layers in the TensorGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topsort(self):\n",
    "  def add_layers_to_list(layer, sorted_layers):\n",
    "    if layer in sorted_layers:\n",
    "      return\n",
    "    for in_layer in layer.in_layers:\n",
    "      add_layers_to_list(in_layer, sorted_layers)\n",
    "    sorted_layers.append(layer)\n",
    "  sorted_layers = []\n",
    "  for l in self.features + self.labels + self.task_weights + self.outputs:\n",
    "    add_layers_to_list(l, sorted_layers)\n",
    "  add_layers_to_list(self.loss, sorted_layers)\n",
    "  return sorted_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build() method takes the responsibility of populating the tf.Graph instance by calling layer.create_tensor for each layer in topological order (Example 8-12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-12. The build method populates the underlying TensorFlow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(self):\n",
    "  if self.built:\n",
    "    return\n",
    "  with self._get_tf(\"Graph\").as_default():\n",
    "    self._training_placeholder = tf.placeholder(dtype=tf.float32, shape=())\n",
    "    if self.random_seed is not None:\n",
    "      tf.set_random_seed(self.random_seed)\n",
    "    for layer in self.topsort():\n",
    "      with tf.name_scope(layer.name):\n",
    "        layer.create_tensor(training=self._training_placeholder)\n",
    "    self.session = tf.Session()\n",
    "    self.built = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method set_loss() adds a loss for training to the graph. add_output() specifies that the layer in question might be fetched from the graph. set_optimizer() specifies the optimizer used for training (Example 8-13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-13. These methods add necessary losses, outputs, and optimizers to the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_loss(self, layer):\n",
    "  self._add_layer(layer)\n",
    "  self.loss = layer\n",
    "def add_output(self, layer):\n",
    "  self._add_layer(layer)\n",
    "  self.outputs.append(layer)\n",
    "def set_optimizer(self, optimizer):\n",
    "  \"\"\"Set the optimizer to use for fitting.\"\"\"\n",
    "  self.optimizer = optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method get_layer_variables() is used to fetch the learnable tf.Variable objects created by a layer. The private method _get_tf is used to fetch the tf.Graph and optimizer instances underpinning the TensorGraph. get_global_step is a convenience method for fetching the current step in the training process (starting from 0 at construction). See Example 8-14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-14. Fetch the learnable variables associated with each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_variables(self, layer):\n",
    "  \"\"\"Get the list of trainable variables in a layer of the graph.\"\"\"\n",
    "  if not self.built:\n",
    "    self.build()\n",
    "  with self._get_tf(\"Graph\").as_default():\n",
    "    if layer.variable_scope == \"\":\n",
    "      return []\n",
    "    return tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=layer.variable_scope)\n",
    "def get_global_step(self):\n",
    "  return self._get_tf(\"GlobalStep\")\n",
    "def _get_tf(self, obj):\n",
    "  \"\"\"Fetches underlying TensorFlow primitives.\n",
    "  Parameters\n",
    "  ----------\n",
    "  obj: str\n",
    "    If \"Graph\", returns tf.Graph instance. If \"Optimizer\", returns the\n",
    "    optimizer. If \"train_op\", returns the train operation. If \"GlobalStep\" returns\n",
    "    the global step.\n",
    "  Returns\n",
    "  -------\n",
    "  TensorFlow Object\n",
    "  \"\"\"\n",
    "  if obj in self.tensor_objects and self.tensor_objects[obj] is not None:\n",
    "    return self.tensor_objects[obj]\n",
    "  if obj == \"Graph\":\n",
    "    self.tensor_objects[\"Graph\"] = tf.Graph()\n",
    "  elif obj == \"Optimizer\":\n",
    "    self.tensor_objects[\"Optimizer\"] = tf.train.AdamOptimizer(\n",
    "        learning_rate=self.learning_rate,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "        epsilon=1e-7)\n",
    "  elif obj == \"GlobalStep\":\n",
    "    with self._get_tf(\"Graph\").as_default():\n",
    "      self.tensor_objects[\"GlobalStep\"] = tf.Variable(0, trainable=False)\n",
    "  return self._get_tf(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the restore() method restores a saved TensorGraph from disk (Example 8-15). (As you will see later, the TensorGraph is saved automatically during training.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8-15. Restore a trained model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore(self):\n",
    "  \"\"\"Reload the values of all variables from the most recent checkpoint file.\"\"\"\n",
    "  if not self.built:\n",
    "    self.build()\n",
    "  last_checkpoint = tf.train.latest_checkpoint(self.model_dir)\n",
    "  if last_checkpoint is None:\n",
    "    raise ValueError(\"No checkpoint found\")\n",
    "  with self._get_tf(\"Graph\").as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(self.session, last_checkpoint)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
